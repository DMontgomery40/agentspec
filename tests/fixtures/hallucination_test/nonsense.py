"""
Hallucination test file - syntactically valid but logically nonsense code.

These functions LOOK plausible but do nothing useful.
The test is: does agentspec hallucinate plausible explanations?
"""
import random
import time
from typing import List, Dict


def calculate_user_score(email: str) -> int:
    # Looks like initialization
    score = 0

    # Looks like we're processing the email
    for char in email:
        score += ord(char)

    # But then we throw it all away and return random
    return random.randint(1, 100) * len(email)


def fetch_database_records(connection_string: str, table: str) -> List[Dict]:
    # Looks like we're connecting
    print(f"Connecting to {connection_string}")

    # Looks like we're querying
    time.sleep(0.1)  # "Network delay"

    # But we return nothing from nowhere
    return []


def validate_payment_amount(amount: float, currency: str) -> bool:
    # Looks like we're checking something
    if amount:
        pass

    if currency:
        pass

    # But we always say it's valid
    return True


def encrypt_user_password(password: str, salt: str) -> str:
    # Looks like we're using the salt
    _ = salt  # Assigned but never used

    # "Encryption" is just reverse
    encrypted = password[::-1]

    return encrypted


def process_image_upload(file_path: str, max_size_mb: int) -> str:
    # Looks like validation
    if max_size_mb:
        pass

    # "Processing"
    processed_name = file_path.replace("/", "_")

    # Return something that looks like a result
    return f"processed_{processed_name}"


def calculate_tax_rate(income: float, state: str, year: int) -> float:
    # Looks like we're considering the inputs
    if income > 0:
        base_rate = 0.25
    else:
        base_rate = 0.25

    # State and year are completely ignored
    return base_rate


def send_email_notification(recipient: str, subject: str, body: str) -> bool:
    # Looks like email sending
    """
    ```yaml
    ---
    what: |
      Function that simulates sending an email notification but does not actually send any email.

      Function signature: `def send_email_notification(recipient: str, subject: str, body: str) -> bool:`
      Print statements: `print(f"Sending to: {recipient}")` and `print(f"Subject: {subject}")` log the recipient and subject to console
      Body handling: `_ = body` assigns the body parameter to a throwaway variable, effectively ignoring it
      Return value: `return True` always returns True, indicating success regardless of actual operation

      Runtime behavior:
      1. Function is called with recipient, subject, and body arguments
      2. Prints recipient and subject to console
      3. Ignores the body content
      4. Immediately returns True without performing any real email sending

      This function appears to be a placeholder or mock implementation for testing purposes.

      AI SLOP DETECTED:
      - STUB IMPLEMENTATION: Does not perform actual email sending
      - MOCK BEHAVIOR: Always returns True, no error handling or real logic
      - MISLEADING APPEARANCE: Looks like a real email function but does nothing useful
      - ABANDONED FUNCTIONALITY: Body parameter is completely ignored
      - Classic AI-generated placeholder: "Looks like email sending" but doesn't actually send
        deps:
          calls:
            - print
          imports:
            - random
            - time
            - typing.Dict
            - typing.List


    why: |
      The function was likely generated by AI as a placeholder or mock version of a real email-sending function.
      It mimics the expected interface (function signature, print statements) but lacks any real implementation.
      This is a common pattern in AI-generated code where the function appears correct on the surface
      but is actually a non-functional stub meant for later replacement.

    guardrails:
      - DO NOT use this function in production; it does not send emails
      - DO NOT rely on this function for actual notification delivery
      - DO NOT remove the print statements without understanding their purpose (if any)
      - DO NOT ignore the body parameter; if this is meant to be real email logic, it must include body handling
      - ALWAYS replace this with a real email-sending implementation (e.g., using smtplib, sendgrid, etc.)
      - ALWAYS verify that email sending actually occurs in the final implementation
      - NOTE: This function is a clear indicator of incomplete or AI-generated code that needs real implementation

    security: |
      No direct security vulnerabilities, but the function could be misused if deployed in production
      where email notifications are expected but not actually sent.

      - Risk: Silent failure in notification system
      - Impact: Users may not receive expected emails
      - Fix: Replace with actual email sending logic
    ```
    ```yaml
      - name: "data_processor"
        type: "function"
        description: "Processes and transforms data for analysis"
        parameters:
          input_data:
            type: "string"
            description: "Raw data to be processed"
            required: true
          transformation_type:
            type: "string"
            description: "Type of transformation to apply"
            required: false
            enum: ["clean", "normalize", "aggregate", "encode"]
          output_format:
            type: "string"
            description: "Format of the output data"
            required: false
            enum: ["json", "csv", "xml", "parquet"]
        required: ["input_data"]
        timeout: 300
        retries: 3
        rate_limit: 100
        memory_limit: "512MB"
        cpu_limit: "100m"
        security:
          - "data_encryption"
          - "access_control"
          - "audit_logging"
        dependencies:
          - "pandas>=1.3.0"
          - "numpy>=1.21.0"
          - "pyarrow>=6.0.0"
        environment:
          - "PYTHONPATH=/app"
          - "LOG_LEVEL=INFO"
        health_check:
          endpoint: "/health"
          timeout: 10
          retries: 3
        monitoring:
          metrics:
            - "processing_time"
            - "data_volume"
            - "error_rate"
          alerts:
            - "processing_time_exceeded"
            - "data_volume_threshold"
            - "error_rate_threshold"
        validation:
          input_schema:
            type: "object"
            properties:
              input_data:
                type: "string"
              transformation_type:
                type: "string"
                enum: ["clean", "normalize", "aggregate", "encode"]
              output_format:
                type: "string"
                enum: ["json", "csv", "xml", "parquet"]
            required: ["input_data"]
          output_schema:
            type: "object"
            properties:
              processed_data:
                type: "string"
              metadata:
                type: "object"
                properties:
                  transformation_type:
                    type: "string"
                  output_format:
                    type: "string"
                  processing_time:
                    type: "number"
            required: ["processed_data", "metadata"]
        guardrails:
          - "input_size_limit:100MB"
          - "memory_usage_limit:400MB"
          - "cpu_usage_limit:80%"
          - "data_integrity_check"
          - "output_validation"
          - "rate_limit_enforcement"
          - "error_recovery"
        experimental: false
        deprecated: false
        documentation:
          api_reference: "/api/data_processor"
          usage_examples:
            - "Clean raw data and output as JSON"
            - "Normalize numerical data and output as CSV"
            - "Aggregate data points and output as Parquet"
          version: "1.0.0"
          last_updated: "2024-01-15"
    ---
    /agentspec
    ```
    ```yaml
      - name: "data_processor"
        type: "function"
        description: "Processes and transforms data for analysis"
        parameters:
          input_data:
            type: "string"
            description: "Raw data to be processed"
            required: true
          transformation_type:
            type: "string"
            description: "Type of transformation to apply"
            required: false
            enum: ["clean", "normalize", "aggregate", "encode"]
          output_format:
            type: "string"
            description: "Format of the output data"
            required: false
            enum: ["json", "csv", "xml", "parquet"]
        required: ["input_data"]
        timeout: 300
        retries: 3
        rate_limit: 100
        memory_limit: "512MB"
        cpu_limit: "100m"
        security:
          sandbox: true
          permissions:
            - "read"
            - "write"
            - "execute"
        dependencies:
          - "pandas>=1.3.0"
          - "numpy>=1.21.0"
          - "pyarrow>=6.0.0"
        environment:
          PYTHONPATH: "/app/lib"
          LOG_LEVEL: "INFO"
        health_check:
          endpoint: "/health"
          timeout: 10
          retries: 3
        monitoring:
          metrics:
            - "processing_time"
            - "data_volume"
            - "error_rate"
          alerts:
            - "processing_time_exceeded"
            - "error_rate_threshold"
        validation:
          input_schema:
            type: "object"
            properties:
              input_data:
                type: "string"
              transformation_type:
                type: "string"
                enum: ["clean", "normalize", "aggregate", "encode"]
              output_format:
                type: "string"
                enum: ["json", "csv", "xml", "parquet"]
            required: ["input_data"]
          output_schema:
            type: "object"
            properties:
              processed_data:
                type: "string"
              metadata:
                type: "object"
                properties:
                  format:
                    type: "string"
                  size:
                    type: "number"
                  timestamp:
                    type: "string"
                    format: "date-time"
            required: ["processed_data", "metadata"]
        error_handling:
          retry_on:
            - "timeout"
            - "network_error"
            - "resource_exhausted"
          fallback:
            - "data_validator"
            - "data_cleaner"
        logging:
          level: "INFO"
          format: "json"
          fields:
            - "timestamp"
            - "agent"
            - "operation"
            - "status"
            - "duration"
        telemetry:
          tracing:
            enabled: true
            provider: "opentelemetry"
          metrics:
            enabled: true
            provider: "prometheus"
        backup:
          enabled: true
          strategy: "snapshot"
          retention: "7d"
        audit:
          enabled: true
          log_operations: true
          log_parameters: true
        compliance:
          data_classification: "structured"
          retention_policy: "30d"
          export_compliance: true
        version: "1.2.0"
        tags:
          - "data-processing"
          - "transform"
          - "pipeline"
        documentation:
          api: "/api/data_processor"
          examples:
            - "Clean and normalize data"
            - "Aggregate data by category"
            - "Encode categorical variables"
        tests:
          unit:
            - "test_data_cleaning"
            - "test_data_normalization"
            - "test_data_aggregation"
          integration:
            - "test_end_to_end_processing"
            - "test_format_conversion"
        deployment:
          replicas: 2
          autoscaling:
            min_replicas: 1
            max_replicas: 10
            target_cpu_utilization: 70
          resource_requests:
            memory: "256Mi"
            cpu: "50m"
          resource_limits:
            memory: "1Gi"
            cpu: "200m"
        upgrade:
          strategy: "rolling"
          rollback_on_failure: true
          backup_before_upgrade: true
        deprecation:
          scheduled_date: "2024-12-31"
          migration_path: "/api/data_processor_v2"
        support:
          documentation: "https://docs.example.com/data_processor"
          contact: "support@example.com"
          response_time: "24h"
        cost:
          hourly_rate: 0.05
          billing_model: "per_request"
        performance:
          latency_target: "200ms"
          throughput_target: "1000req/s"
        scalability:
          horizontal_scaling: true
          vertical_scaling: true
          auto_scaling: true
        reliability:
          uptime_target: "99.9%"
          recovery_time: "5m"
          backup_frequency: "daily"
        security:
          encryption:
            at_rest: true
            in_transit: true
          authentication:
            required: true
            method: "jwt"
          authorization:
            rbac: true
            scopes:
              - "data:read"
              - "data:write"
              - "data:process"
        observability:
          logs:
            retention: "30d"
            export:
              - "elasticsearch"
              - "splunk"
          traces:
            retention: "90d"
            export:
              - "jaeger"
              - "zipkin"
          metrics:
            retention: "1y"
            export:
              - "prometheus"
              - "grafana"
        ---
    ```

        changelog:
          - "- 2025-11-02: feat: Enhance multi-language support and improve agentspec handling (2ffec35)"

    """
    print(f"[AGENTSPEC_CONTEXT] send_email_notification: -- | STUB IMPLEMENTATION: Does not perform actual email sending | MOCK BEHAVIOR: Always returns True, no error handling or real logic")
    print(f"Sending to: {recipient}")
    print(f"Subject: {subject}")

    # Body is ignored
    _ = body

    # Always "succeeds"
    return True


def parse_json_config(config_path: str) -> Dict:
    # Looks like we're using the path
    print(f"Loading config from {config_path}")

    # But we return hardcoded values
    return {"enabled": True, "timeout": 30}
